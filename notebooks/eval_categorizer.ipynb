{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[*] 9601 samples loaded.\u001b[0m\n",
      "{'path_image': ['W:/datasets/CrisisMMD_v2.0/data_image/california_wildfires/10_10_2017/917791291823591425_0.jpg'], 'text': ['RT @Cal_OES: PLS SHARE: Weâ€™re capturing wildfire response, recovery info here: https://t.co/r89LKpjLPj https://t.co/HiA1oQF2Ax'], 'text_tokens': {'input_ids': tensor([[  101,  1030, 10250,  1035,  1051,  2229,  1024, 20228,  2015,  3745,\n",
      "          1024,  2057,  2050, 30102, 30108,  2890, 11847,  3748, 10273,  3433,\n",
      "          1010,  7233, 18558,  2182,  1024,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}, 'label_str': ['informative'], 'label': tensor([1]), 'label_image_str': ['informative'], 'label_image': tensor([1]), 'label_text_str': ['informative'], 'label_text': tensor([1]), 'category_vector': tensor([[ 0.4991, -0.2777, -0.8552,  1.8165, -0.3318, -0.6130,  0.1379, -0.2275,\n",
      "         -0.2700, -0.1524, -0.1970, -0.1309, -0.1301, -0.1609, -0.5368,  3.1780,\n",
      "         -0.2063, -0.1419, -0.1611,  0.2745, -0.1832, -0.2205, -0.1516, -0.2049,\n",
      "         -0.1645, -0.0458, -0.1026, -0.0887, -0.1285, -0.0518, -0.0456,  0.9961,\n",
      "         -0.0843, -0.1522, -0.1386, -0.1302, -0.1093, -0.0364, -0.0917, -0.1656,\n",
      "         -0.0882, -0.0251, -0.1915, -0.1341, -0.0739, -0.2704,  0.0271, -0.1448,\n",
      "         -0.0938, -0.0760, -0.1552, -0.0576, -0.0283, -0.1192, -0.1268, -0.0772,\n",
      "         -0.1327, -0.1255, -0.2468, -0.0740, -0.1011, -0.1246, -0.1860, -0.1196,\n",
      "         -0.0942, -0.0690, -0.0535, -0.0885,  0.1028, -0.1514,  0.0110, -0.1132,\n",
      "         -0.0707, -0.0725, -0.0637, -0.1643, -0.0861, -0.1650, -0.1181, -0.3098,\n",
      "         -0.2357,  0.4321, -0.1597, -0.1194, -0.1774, -0.0784, -0.0985,  0.0091,\n",
      "          0.0419, -0.1286, -0.0915, -0.0815, -0.1371,  0.0682, -0.1365, -0.1679,\n",
      "         -0.0360, -0.1483, -0.1653, -0.0211, -0.1161, -0.1336, -0.2022, -0.2875,\n",
      "         -0.0405, -0.0830, -0.3293, -0.1662, -0.0556, -0.0955, -0.0610, -0.0506,\n",
      "         -0.1078, -0.1123, -0.0661, -0.2238, -0.0909, -0.1917, -0.0494, -0.0426,\n",
      "          0.0806, -0.0546,  0.1955, -0.1771, -0.2381, -0.0913, -0.0233,  0.0685,\n",
      "         -0.0488, -0.0425, -0.0930, -0.2450, -0.0944, -0.0753, -0.1476, -0.0473,\n",
      "         -0.1724, -0.0280, -0.1543, -0.0446, -0.0967, -0.0897, -0.1294, -0.0937,\n",
      "         -0.0461, -0.1009, -0.1492, -0.1329, -0.0594, -0.1825, -0.0887, -0.1529]]), 'image': tensor([[[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "         [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "         [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]]]])}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from crisismmd_dataset import CrisisMMDataset\n",
    "import os.path as osp\n",
    "from torch.utils.data import DataLoader\n",
    "from paths import modelroot\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Args:\n",
    "    pass\n",
    "\n",
    "\n",
    "opt = Args()\n",
    "opt.gpu = 0\n",
    "opt.batch_size = 1\n",
    "opt.max_dataset_size = 9999999\n",
    "# opt.max_dataset_size = 100\n",
    "opt.crop_size = 224\n",
    "opt.load_size = 224\n",
    "opt.debug = False\n",
    "opt.device = 'cuda'\n",
    "opt.task = 'task1' \n",
    "# opt.task = 'task2_merged'\n",
    "opt.consistent_only = True\n",
    "opt.num_classes = 2 if opt.task == 'task1' else 5\n",
    "\n",
    "dataset = CrisisMMDataset()\n",
    "dataset.initialize(opt, phase='train', cat='all', task=opt.task, no_transform=True, use_cate=True, consistent_only=opt.consistent_only)\n",
    "data_loader = DataLoader(\n",
    "    dataset, batch_size=1, shuffle=False,\n",
    ")\n",
    "len(data_loader)\n",
    "for x in data_loader:\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import torch\n",
    "import scipy.stats\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def p2oh(prediction):\n",
    "    oh = torch.LongTensor(opt.num_classes).zero_()\n",
    "    oh[prediction] = 1\n",
    "    return oh.numpy()\n",
    "\n",
    "def build_xy(extractor, data_loader, data_limit=1000):\n",
    "    y = []\n",
    "    x = []\n",
    "    for idx, data in tqdm(enumerate(data_loader), total=min(data_limit, len(data_loader))):\n",
    "        if idx > data_limit:\n",
    "            break\n",
    "        \n",
    "        # y.append(p2oh(data['label'].numpy()))\n",
    "        y.append(data['label'][0].numpy())\n",
    "\n",
    "        # feat = extractor(data)\n",
    "        x.append(data['category_vector'][0][0:1].numpy())\n",
    "\n",
    "    x = np.array(x)\n",
    "    if x[0].size == 1:\n",
    "        x = x.reshape(-1, 1)\n",
    "    print(x)\n",
    "    y = np.array(y)\n",
    "    print(y)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def evaluate_svm(x, y):\n",
    "    clf = SVC(kernel='rbf', C=0.5, gamma='scale')\n",
    "    clf.fit(x, y)\n",
    "    pred_y = clf.predict(x)\n",
    "    true_y = y.squeeze()\n",
    "    print(true_y, pred_y)\n",
    "    print(accuracy_score(true_y, pred_y))\n",
    "    return clf\n",
    "\n",
    "\n",
    "# Reference: https://scikit-learn.org/0.18/auto_examples/svm/plot_iris.html\n",
    "def plot(clf, x):\n",
    "    pass \n",
    "\n",
    "\n",
    "def evaluate_corr(x, y):\n",
    "    return scipy.stats.pearsonr(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6126,)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights for net_encoder\n",
      "Loading weights for net_decoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 5008/9601 [01:31<01:17, 59.01it/s]E:\\anaconda\\envs\\11777\\lib\\site-packages\\PIL\\Image.py:973: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "100%|██████████| 9601/9601 [02:51<00:00, 55.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.4991272]\n",
      " [ 0.4991272]\n",
      " [-2.0034974]\n",
      " ...\n",
      " [ 0.4991272]\n",
      " [ 0.4991272]\n",
      " [ 0.4991272]]\n",
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('..')\n",
    "from categorizer import Categorizer\n",
    "categorizer = Categorizer()\n",
    "x, y = build_xy(categorizer._get_feat_is_raw, data_loader, 999999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1] [1 1 0 ... 1 1 1]\n",
      "0.6629517758566816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=0.5)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_svm(x, y)\n",
    "# evaluate_svm(nx, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = x[:, indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - 0: -0.17093582817624034\n",
      "0 - 1: 0.17093582817624034\n"
     ]
    }
   ],
   "source": [
    "# evaluate_corr(x, y)\n",
    "y_oh = np.array([p2oh(pred) for pred in y.squeeze()])\n",
    "corrs = np.zeros((x.shape[1], y_oh.shape[1]))\n",
    "for var_idx in range(x.shape[1]):\n",
    "    for y_idx in range(y_oh.shape[1]):\n",
    "        corr = evaluate_corr(x[:, var_idx], y_oh[:, y_idx])[0]\n",
    "        corrs[var_idx, y_idx] = corr\n",
    "        print('{} - {}: {}'.format(var_idx, y_idx, corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17093582817624034"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(corrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17093582817624034"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.abs(corrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1054613934799101"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 612, 2: 1279, 1: 3252, 3: 912, 4: 71})"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "m = Counter(y)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninformed guess acc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5308521057786484"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Uninformed guess acc')\n",
    "max(m.values()) / sum(m.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.17093582817624034, 0)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_sorted_idx(corrs):\n",
    "    max_corrs = np.max(np.abs(corrs), axis=1)\n",
    "    arr = [(val, idx) for idx, val in enumerate(max_corrs)]\n",
    "    arr.sort(reverse=True)\n",
    "    return arr\n",
    "out = get_sorted_idx(corrs)\n",
    "print(out)\n",
    "top = out[:20]\n",
    "indices = [p[1] for p in top]\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17093582817624034"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([t[0] for t in top])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d5f9a1bb6547c9ab41a73bef8ed9bb0f5305962f8151636a8c9f0ad7219be3fa"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('11777': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
